{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjrRjgcHldnd",
        "outputId": "5949e895-7907-45bb-ff3f-6148dea241b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/speech_course/assignment1\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/IlyaBolkisev/speech_course\n",
        "%cd speech_course/assignment1/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Implement a PyTorch layer"
      ],
      "metadata": {
        "id": "wpZiP8UCqb5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "from melbanks import LogMelFilterBanks"
      ],
      "metadata": {
        "id": "ajKluGx8q49N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signal, sr = torchaudio.load('../assignment2/examples/sample1.wav')\n",
        "signal.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCmml273q5Wh",
        "outputId": "58039139-40b3-42f7-e33e-7e48ba0d7f39"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 243520])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "melspec = torchaudio.transforms.MelSpectrogram(\n",
        "    hop_length=160,\n",
        "    n_mels=80\n",
        ")(signal)\n",
        "logmelbanks = LogMelFilterBanks()(signal)\n",
        "\n",
        "assert torch.log(melspec + 1e-6).shape == logmelbanks.shape\n",
        "assert torch.allclose(torch.log(melspec + 1e-6), logmelbanks)"
      ],
      "metadata": {
        "id": "UbrEQBsmnTyO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Train a simple CNN model"
      ],
      "metadata": {
        "id": "OAmIzZkDqskW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from thop import profile\n",
        "\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchaudio.datasets import SPEECHCOMMANDS"
      ],
      "metadata": {
        "id": "-gIQX4vjpcRu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "FgZExE7Zu1kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpeechDataset(Dataset):\n",
        "    def __init__(self, root, subset):\n",
        "        self.data = SPEECHCOMMANDS(root=root, download=True, subset=subset)\n",
        "\n",
        "        self._yes_no_indices = []\n",
        "        for i in tqdm(range(len(self.data))):\n",
        "            _, _, label, _, _ = self.data[i]\n",
        "            if label.lower() in ['yes', 'no']:\n",
        "                self._yes_no_indices.append(i)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        real_idx = self._yes_no_indices[idx]\n",
        "        waveform, label, *_ = self.data[real_idx]\n",
        "        target = 0 if label == 'no' else 1\n",
        "        return waveform, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._yes_no_indices)"
      ],
      "metadata": {
        "id": "k9ebAQuorfc-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch, max_len=16000):\n",
        "    waveforms = []\n",
        "    targets = []\n",
        "    for (waveform, label) in batch:\n",
        "        if waveform.shape[1] > max_len:\n",
        "            waveform = waveform[:, :max_len]\n",
        "        elif waveform.shape[1] < max_len:\n",
        "            pad_length = max_len - waveform.shape[1]\n",
        "            waveform = torch.nn.functional.pad(waveform, (0, pad_length))\n",
        "        waveforms.append(waveform)\n",
        "        targets.append(label)\n",
        "\n",
        "    waveforms = torch.stack(waveforms, dim=0)\n",
        "    targets = torch.tensor(targets, dtype=torch.long)\n",
        "    waveforms = waveforms.squeeze(1)\n",
        "    return waveforms, targets\n",
        "\n",
        "data_dir = './'\n",
        "\n",
        "train_dataset = SpeechDataset(data_dir, subset='training')\n",
        "val_dataset = SpeechDataset(data_dir, subset='validation')\n",
        "test_dataset = SpeechDataset(data_dir, subset='testing')\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmN1urLPsR4m",
        "outputId": "559a433e-516d-4223-c51b-ab93fac1c6fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 84843/84843 [06:08<00:00, 229.94it/s]\n",
            "100%|██████████| 9981/9981 [00:35<00:00, 284.43it/s]\n",
            "100%|██████████| 11005/11005 [00:39<00:00, 280.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Init model"
      ],
      "metadata": {
        "id": "XUkkO8Xq31K9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpeechModel(nn.Module):\n",
        "    def __init__(self, n_mels=40, groups=1, num_classes=2):\n",
        "        super(SpeechModel, self).__init__()\n",
        "        self.n_mels = n_mels\n",
        "\n",
        "        self.logmel = LogMelFilterBanks(n_mels=n_mels)\n",
        "\n",
        "        self.conv1 = nn.Conv1d(n_mels, 32, 3, padding=1, groups=groups)\n",
        "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(32, 64, 3, padding=1, groups=groups)\n",
        "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(64, 128, 3, padding=1, groups=groups)\n",
        "        self.pool3 = nn.AdaptiveMaxPool1d(1)\n",
        "\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.logmel(x)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = torch.nn.functional.relu(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = torch.nn.functional.relu(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = torch.nn.functional.relu(x)\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = x.squeeze(-1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2pgW6MYZvRB2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def compute_flops(model, input_tensor):\n",
        "    flops, params = profile(model, inputs=(input_tensor,))\n",
        "    return flops"
      ],
      "metadata": {
        "id": "aUB6ULk-4QPx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "zSmMLZjS5hLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" )\n",
        "model = SpeechModel(n_mels=40, groups=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses = []\n",
        "val_accuracies = []\n",
        "epoch_times = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_start = time.time()\n",
        "    running_loss = 0.0\n",
        "    total_train_samples = 0\n",
        "\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        total_train_samples += inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total_train_samples\n",
        "    train_losses.append(epoch_loss)\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    epoch_times.append(epoch_time)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            correct += (preds == targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "    val_acc = correct / total\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_loss:.4f}, Val Acc: {val_acc:.4f}, Epoch Time: {epoch_time:.2f} sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfwtlkJR5fAr",
        "outputId": "18d0e6cc-e89c-4a11-921c-5ea0d8a6f6a7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Train Loss: 0.0022, Val Acc: 1.0000, Epoch Time: 23.33 sec\n",
            "Epoch 2/10 - Train Loss: 0.0000, Val Acc: 1.0000, Epoch Time: 22.05 sec\n",
            "Epoch 3/10 - Train Loss: 0.0000, Val Acc: 1.0000, Epoch Time: 21.97 sec\n",
            "Epoch 4/10 - Train Loss: 0.0000, Val Acc: 1.0000, Epoch Time: 22.03 sec\n",
            "Epoch 5/10 - Train Loss: 0.0000, Val Acc: 1.0000, Epoch Time: 22.05 sec\n",
            "Epoch 6/10 - Train Loss: 0.0000, Val Acc: 1.0000, Epoch Time: 22.08 sec\n",
            "Epoch 7/10 - Train Loss: 0.0000, Val Acc: 1.0000, Epoch Time: 22.11 sec\n",
            "Epoch 8/10 - Train Loss: 0.0000, Val Acc: 1.0000, Epoch Time: 21.94 sec\n",
            "Epoch 9/10 - Train Loss: 0.0000, Val Acc: 1.0000, Epoch Time: 21.84 sec\n",
            "Epoch 10/10 - Train Loss: 0.0000, Val Acc: 1.0000, Epoch Time: 21.67 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        correct += (preds == targets).sum().item()\n",
        "        total += targets.size(0)\n",
        "test_acc = correct / total\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDE2sR0e5r5p",
        "outputId": "f2c70f19-7e4a-4d1e-9ebc-322ea3dfa1a6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_params = count_parameters(model)\n",
        "print(\"Trainable parameters:\", num_params)\n",
        "sample_input = next(iter(train_loader))[0][:1].to(device)\n",
        "flops = compute_flops(model, sample_input)\n",
        "print(\"FLOPs:\", flops)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c9YujW15s4Y",
        "outputId": "e8f1eba9-7373-4780-fb3d-69091934b55c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 35042\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.AdaptiveMaxPool1d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "FLOPs: 1309696.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YacXu-qf5vJU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}