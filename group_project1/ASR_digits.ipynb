{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":99036,"databundleVersionId":11819802,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport math\nimport random\nfrom pathlib import Path\nfrom itertools import groupby\n\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport torch\nfrom torch import nn, optim\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import Dataset, DataLoader\nimport torchaudio\nfrom torchaudio.transforms import FrequencyMasking, TimeMasking, Vol\nfrom torchmetrics.text import CharErrorRate","metadata":{"_uuid":"1572226d-e007-447b-9f6d-09f26f33e9e7","_cell_guid":"38379e69-2ae2-4b5c-8e6f-521e7dfff056","trusted":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-20T12:38:14.449576Z","iopub.execute_input":"2025-04-20T12:38:14.449900Z","iopub.status.idle":"2025-04-20T12:38:27.360922Z","shell.execute_reply.started":"2025-04-20T12:38:14.449872Z","shell.execute_reply":"2025-04-20T12:38:27.360158Z"},"id":"Fxo0WqOi2Sf0","collapsed":false},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class Config:\n    folder = Path(\"/kaggle/input/asr-numbers-recognition-in-russian/\")\n\n    target_samplerate = 16000\n    n_mels = 80\n    n_fft = 400\n    hop_length = 160\n    max_frames = 1000\n\n    hidden = 128\n    num_layers = 2\n    dropout = 0.2\n\n    batch_size = 32\n    num_epochs = 10\n    lr = 1e-3\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ncfg = Config()","metadata":{"_uuid":"b3f30879-6669-4883-b121-0a7bbda278e5","_cell_guid":"789486d4-96e0-41c5-ae2f-1d9b1e499992","trusted":true,"jupyter":{"outputs_hidden":false},"id":"McOiLumg2Sf1","collapsed":false,"execution":{"iopub.status.busy":"2025-04-20T12:38:27.362496Z","iopub.execute_input":"2025-04-20T12:38:27.362998Z","iopub.status.idle":"2025-04-20T12:38:27.424126Z","shell.execute_reply.started":"2025-04-20T12:38:27.362971Z","shell.execute_reply":"2025-04-20T12:38:27.423359Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Load data","metadata":{"_uuid":"f91e75e6-bc81-40b9-b3c1-f5dda7e567ab","_cell_guid":"b563d4ec-5aa4-4632-8106-277013b46dad","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"id":"t_5Sfi6W2Sf1"}},{"cell_type":"code","source":"class NumberTokenizer:\n    def __init__(self):\n        self.labels = ['<blank>'] + [str(d) for d in range(10)]\n        self.token2idx = {t: i for i, t in enumerate(self.labels)}\n        self.idx2token = {i: t for t, i in self.token2idx.items()}\n\n    def encode(self, text):\n        return [self.token2idx[c] for c in text]\n\n    def decode(self, logits: torch.Tensor, greedy=True) -> str:\n        if greedy:\n            logits = torch.argmax(logits, dim=-1).tolist()\n            logits = [idx for idx, _ in groupby(logits) if idx != 0]\n        return \"\".join(self.idx2token[t] for t in logits)\n\n\ntokenizer = NumberTokenizer()","metadata":{"_uuid":"0c42cbf3-0ab0-406b-9e47-21e679a19992","_cell_guid":"ec278b84-f9d5-45c6-9ce4-6dfdbda1ecb7","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:38:27.425003Z","iopub.execute_input":"2025-04-20T12:38:27.425437Z","iopub.status.idle":"2025-04-20T12:38:27.455721Z","shell.execute_reply.started":"2025-04-20T12:38:27.425410Z","shell.execute_reply":"2025-04-20T12:38:27.454990Z"},"jupyter":{"outputs_hidden":false},"id":"-0SrQ1u12Sf2","collapsed":false},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class NumbersDataset(Dataset):\n    def __init__(self, folder, subset, tokenizer, config, augment=False):\n        self.df = pd.read_csv(folder / f\"{subset}.csv\")\n        self.folder = folder\n        self.tokenizer = tokenizer\n        self.config = config\n        self.augment = augment\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        wav_path = self.folder / row.filename\n        waveform, sr = torchaudio.load(wav_path)\n\n        if sr != self.config.target_samplerate:\n            waveform = torchaudio.transforms.Resample(sr, self.config.target_samplerate)(waveform)\n\n        waveform = waveform.mean(dim=0, keepdim=True)\n\n        if self.augment:\n            waveform += 0.003 * torch.randn_like(waveform)\n            waveform = Vol(random.uniform(-6, 6), gain_type='db')(waveform)\n            shift = int(random.uniform(-0.1, 0.1) * waveform.size(1))\n            waveform = torch.roll(waveform, shift, dims=-1)\n\n        melspec = torchaudio.transforms.MelSpectrogram(\n            sample_rate=self.config.target_samplerate,\n            n_mels=self.config.n_mels,\n            n_fft = self.config.n_fft,\n            hop_length = self.config.hop_length\n        )(waveform)\n        melspec = torchaudio.transforms.AmplitudeToDB()(melspec)\n        melspec = melspec[..., :self.config.max_frames]\n\n        if self.augment:\n            melspec = FrequencyMasking(freq_mask_param=15)(melspec)\n            melspec = TimeMasking(time_mask_param=35)(melspec)\n\n        melspec = melspec.squeeze(0).transpose(0, 1)\n        target = torch.tensor(self.tokenizer.encode(str(row.transcription)), dtype=torch.long)\n        return melspec, target, row.spk_id\n\ndef collate_fn(batch):\n    X, y, ids   = zip(*batch)\n    X_len = torch.tensor([e.size(0) for e in X], dtype=torch.long)\n    X_pad = pad_sequence(X, batch_first=True)\n\n    y_len = torch.tensor([e.size(0) for e in y], dtype=torch.long)\n    y = torch.cat(y)\n    return X_pad, X_len, y, y_len, ids","metadata":{"_uuid":"7afe4e53-3fb4-4c80-9142-8233f86fc1d3","_cell_guid":"f2225e78-7e17-4fd7-a291-050e086fb0a7","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:38:27.456509Z","iopub.execute_input":"2025-04-20T12:38:27.456782Z","iopub.status.idle":"2025-04-20T12:38:27.472072Z","shell.execute_reply.started":"2025-04-20T12:38:27.456758Z","shell.execute_reply":"2025-04-20T12:38:27.471337Z"},"jupyter":{"outputs_hidden":false},"id":"3J5tewVj2Sf2","collapsed":false},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_ds = NumbersDataset(cfg.folder, 'train', tokenizer, cfg, augment=True)\nval_ds = NumbersDataset(cfg.folder, 'dev', tokenizer, cfg, augment=False)\n\ntrain_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, collate_fn=collate_fn)\nval_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, collate_fn=collate_fn)\n\nprint(f\"Train size: {len(train_loader)}, Val size: {len(val_loader)}\")","metadata":{"_uuid":"bc091d3d-c3a2-4f6a-bf96-56dc84627a5a","_cell_guid":"425f3ea4-dd6f-407c-8b96-af79d3e6fda5","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:38:27.474070Z","iopub.execute_input":"2025-04-20T12:38:27.474293Z","iopub.status.idle":"2025-04-20T12:38:27.683638Z","shell.execute_reply.started":"2025-04-20T12:38:27.474270Z","shell.execute_reply":"2025-04-20T12:38:27.682825Z"},"jupyter":{"outputs_hidden":false},"id":"Y7Ca3V8G2Sf2","outputId":"d2ef56ba-278d-4132-89d6-505db7b0c769","collapsed":false},"outputs":[{"name":"stdout","text":"Train size: 393, Val size: 71\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Init model","metadata":{"_uuid":"2fe6ae6f-af96-4648-9c57-34a38fe65602","_cell_guid":"53bf715f-9628-426a-bbe4-6fee23145866","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"id":"1-LcApWN2Sf3"}},{"cell_type":"code","source":"class CRNN(nn.Module):\n    def __init__(self, cfg: Config, vocab_size: int):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(1, 64, (3, 3), padding=(1, 1)),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, (3, 3), padding=(1, 1)),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d((1, 2)),\n            nn.Dropout(cfg.dropout),\n\n            nn.Conv2d(64, 128, (3, 3), padding=(1, 1)),\n            nn.BatchNorm2d(128), nn.ReLU(),\n            nn.MaxPool2d((1, 2)),\n            nn.Dropout(cfg.dropout),\n        )\n        rnn_in = (cfg.n_mels // 4) * 128\n        self.rnn = nn.LSTM(rnn_in, cfg.hidden, num_layers=cfg.num_layers,\n                           bidirectional=True, batch_first=True, dropout=cfg.dropout)\n        self.fc = nn.Linear(cfg.hidden * 2, vocab_size)\n\n    def forward(self, x):\n        x = x.unsqueeze(1)\n        x = self.conv(x)\n        b, c, t, m = x.shape\n\n        x = x.permute(0, 2, 3, 1).reshape(b, t, m * c)\n        x, _ = self.rnn(x)\n        return self.fc(x)\n\n\nmodel = CRNN(cfg, vocab_size=len(tokenizer.labels)).to(cfg.device)","metadata":{"_uuid":"6ae6c372-d873-4890-a961-9778056670e9","_cell_guid":"69ee9029-81a6-4efe-ad88-9b3fca4b0181","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:38:27.684523Z","iopub.execute_input":"2025-04-20T12:38:27.685287Z","iopub.status.idle":"2025-04-20T12:38:27.985048Z","shell.execute_reply.started":"2025-04-20T12:38:27.685262Z","shell.execute_reply":"2025-04-20T12:38:27.984437Z"},"jupyter":{"outputs_hidden":false},"id":"Wt3de75r2Sf3","collapsed":false},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(f\"Model params: {sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6:.2f}â€¯M\")","metadata":{"_uuid":"0dc47c02-89a2-4d75-be72-85b1c1dba8a8","_cell_guid":"8e74941d-35ca-4c24-83a5-b4c2b31eaa08","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:38:27.985727Z","iopub.execute_input":"2025-04-20T12:38:27.985992Z","iopub.status.idle":"2025-04-20T12:38:27.990764Z","shell.execute_reply.started":"2025-04-20T12:38:27.985969Z","shell.execute_reply":"2025-04-20T12:38:27.989964Z"},"jupyter":{"outputs_hidden":false},"id":"8nXIASTX2Sf3","collapsed":false},"outputs":[{"name":"stdout","text":"Model params: 3.26â€¯M\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"ctc_loss = nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)\noptimizer = optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=cfg.lr, epochs=cfg.num_epochs,\n                                          steps_per_epoch=len(train_loader))","metadata":{"_uuid":"94a7af85-e711-4335-84e4-b4fa4c59d64c","_cell_guid":"25ba6ce5-f1d0-41fe-ac32-1f0b8d6f6138","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:38:27.991604Z","iopub.execute_input":"2025-04-20T12:38:27.991876Z","iopub.status.idle":"2025-04-20T12:38:28.005856Z","shell.execute_reply.started":"2025-04-20T12:38:27.991859Z","shell.execute_reply":"2025-04-20T12:38:28.005137Z"},"jupyter":{"outputs_hidden":false},"id":"2r2hP6EF2Sf3","collapsed":false},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Train model","metadata":{"_uuid":"6be5bedb-9af5-4074-8263-9710371b84e1","_cell_guid":"12228386-ac73-4bf9-bc12-7711876f609e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"id":"U1iOJRs32Sf3"}},{"cell_type":"code","source":"cer = CharErrorRate()","metadata":{"_uuid":"27108277-b964-4375-baae-4fa260582b68","_cell_guid":"3df4684c-6536-412e-9ff8-ca9add2f7ddd","trusted":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-20T12:38:28.006692Z","iopub.execute_input":"2025-04-20T12:38:28.007020Z","iopub.status.idle":"2025-04-20T12:38:28.025645Z","shell.execute_reply.started":"2025-04-20T12:38:28.006992Z","shell.execute_reply":"2025-04-20T12:38:28.024956Z"},"id":"bOlgB1Tw2Sf3","collapsed":false},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def train_one_epoch():\n    model.train()\n    total_loss = 0\n    for X, X_len, y, y_len, ids in tqdm(train_loader):\n        X, X_len, y = X.to(cfg.device), X_len.to(cfg.device), y.to(cfg.device)\n        optimizer.zero_grad()\n        X_ = model(X)\n        loss = ctc_loss(X_.log_softmax(-1).transpose(0, 1), y, X_len, y_len)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n        optimizer.step()\n        scheduler.step()\n        total_loss += loss.item()\n    return total_loss / len(train_loader)\n\n\ndef eval_one_epoch():\n    model.eval()\n    spk2preds = dict()\n    spk2gts = dict()\n\n    with torch.no_grad():\n        for X, X_len, y, y_len, ids in val_loader:\n            X = X.to(cfg.device)\n            logits = model(X).cpu()\n\n            targets_split = torch.split(y, y_len.tolist())\n            for i, (logit, tgt, spk) in enumerate(zip(logits, targets_split, ids)):\n                pred_str = tokenizer.decode(logit[:X_len[i]])\n                true_str = tokenizer.decode(tgt.tolist(), greedy=False)\n                if spk not in spk2preds:\n                    spk2preds[spk] = [pred_str]\n                    spk2gts[spk] = [true_str]\n                else:\n                    spk2preds[spk].append(pred_str)\n                    spk2gts[spk].append(true_str)\n\n    per_spk = {s: cer(spk2preds[s], spk2gts[s]).item()\n               for s in spk2preds}\n\n    macro_cer = sum(per_spk.values()) / len(per_spk)\n    return macro_cer, per_spk","metadata":{"_uuid":"62981249-e73d-4bf5-9438-ec84eb4d074a","_cell_guid":"4db15d1c-48b0-4f48-92df-a086cd74ce41","trusted":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-20T12:38:28.026473Z","iopub.execute_input":"2025-04-20T12:38:28.026727Z","iopub.status.idle":"2025-04-20T12:38:28.035747Z","shell.execute_reply.started":"2025-04-20T12:38:28.026706Z","shell.execute_reply":"2025-04-20T12:38:28.035103Z"},"id":"D9RHaxGb2Sf4","collapsed":false},"outputs":[],"execution_count":10},{"cell_type":"code","source":"best_cer = 1.0\nfor epoch in range(1, cfg.num_epochs + 1):\n    train_loss = train_one_epoch()\n    val_cer, per_spk = eval_one_epoch()\n\n    worst = sorted(per_spk.items(), key=lambda x: x[1], reverse=True)[:5]\n    best  = sorted(per_spk.items(), key=lambda x: x[1])[:5]\n    if val_cer < best_cer:\n        best_cer, best_state = val_cer, model.state_dict()\n\n    print(f\"\\nEpoch {epoch} â€”Â val CER {val_cer*100:.2f}% (best {best_cer*100:.2f}%)\")\n    print(\"Worst 5 speakers:\", \", \".join(f\"{s}:{e*100:.1f}%\" for s,e in worst))\n    print(\"Best  5 speakers:\", \", \".join(f\"{s}:{e*100:.1f}%\" for s,e in best))","metadata":{"_uuid":"2692c6a3-55ba-4954-9450-0388f02e94a7","_cell_guid":"09850398-43ab-44e2-9258-7bb8a685bbca","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:38:28.036350Z","iopub.execute_input":"2025-04-20T12:38:28.036551Z","iopub.status.idle":"2025-04-20T13:39:12.536296Z","shell.execute_reply.started":"2025-04-20T12:38:28.036537Z","shell.execute_reply":"2025-04-20T13:39:12.535598Z"},"jupyter":{"outputs_hidden":false},"id":"Y8mNNkiW2Sf4","collapsed":false},"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 393/393 [08:45<00:00,  1.34s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1 â€”Â val CER 100.00% (best 100.00%)\nWorst 5 speakers: spk_J:100.0%, spk_I:100.0%, spk_K:100.0%, spk_H:100.0%, spk_F:100.0%\nBest  5 speakers: spk_J:100.0%, spk_I:100.0%, spk_K:100.0%, spk_H:100.0%, spk_F:100.0%\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 393/393 [05:14<00:00,  1.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2 â€”Â val CER 80.27% (best 80.27%)\nWorst 5 speakers: spk_K:93.0%, spk_C:84.2%, spk_A:83.8%, spk_I:81.4%, spk_D:80.9%\nBest  5 speakers: spk_E:72.0%, spk_B:72.3%, spk_J:76.2%, spk_H:79.1%, spk_F:79.7%\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 393/393 [05:22<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3 â€”Â val CER 38.52% (best 38.52%)\nWorst 5 speakers: spk_K:59.9%, spk_I:45.4%, spk_C:42.6%, spk_F:39.7%, spk_A:38.8%\nBest  5 speakers: spk_B:30.1%, spk_H:30.2%, spk_E:30.7%, spk_J:31.0%, spk_D:36.8%\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 393/393 [05:24<00:00,  1.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4 â€”Â val CER 36.17% (best 36.17%)\nWorst 5 speakers: spk_K:50.3%, spk_I:43.9%, spk_C:38.9%, spk_A:37.9%, spk_F:36.6%\nBest  5 speakers: spk_E:27.5%, spk_H:30.4%, spk_B:31.0%, spk_J:31.3%, spk_D:34.0%\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 393/393 [05:11<00:00,  1.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5 â€”Â val CER 32.07% (best 32.07%)\nWorst 5 speakers: spk_K:45.9%, spk_I:40.2%, spk_A:35.6%, spk_C:34.1%, spk_F:32.5%\nBest  5 speakers: spk_E:21.9%, spk_H:25.6%, spk_J:26.4%, spk_B:27.4%, spk_D:31.1%\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 393/393 [04:59<00:00,  1.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6 â€”Â val CER 29.35% (best 29.35%)\nWorst 5 speakers: spk_K:40.4%, spk_I:37.0%, spk_A:31.8%, spk_D:29.7%, spk_F:29.7%\nBest  5 speakers: spk_E:23.6%, spk_B:23.6%, spk_H:23.9%, spk_J:24.1%, spk_C:29.6%\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 393/393 [05:02<00:00,  1.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7 â€”Â val CER 31.56% (best 29.35%)\nWorst 5 speakers: spk_K:42.2%, spk_I:39.6%, spk_A:34.4%, spk_C:33.9%, spk_F:32.0%\nBest  5 speakers: spk_E:24.5%, spk_H:25.3%, spk_B:25.9%, spk_J:26.6%, spk_D:31.2%\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 393/393 [05:01<00:00,  1.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8 â€”Â val CER 29.97% (best 29.35%)\nWorst 5 speakers: spk_K:40.8%, spk_I:39.4%, spk_C:34.1%, spk_A:30.9%, spk_F:29.5%\nBest  5 speakers: spk_E:22.4%, spk_H:23.7%, spk_B:24.0%, spk_J:26.2%, spk_D:28.7%\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 393/393 [05:03<00:00,  1.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9 â€”Â val CER 28.91% (best 28.91%)\nWorst 5 speakers: spk_K:39.5%, spk_I:37.9%, spk_C:32.9%, spk_A:30.6%, spk_F:28.1%\nBest  5 speakers: spk_H:22.0%, spk_E:22.1%, spk_J:24.2%, spk_B:24.8%, spk_D:27.0%\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 393/393 [04:55<00:00,  1.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10 â€”Â val CER 29.60% (best 28.91%)\nWorst 5 speakers: spk_K:39.2%, spk_I:38.0%, spk_C:34.4%, spk_A:31.3%, spk_F:29.3%\nBest  5 speakers: spk_H:22.4%, spk_E:22.8%, spk_J:24.8%, spk_B:25.2%, spk_D:28.7%\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# Create submission","metadata":{"_uuid":"39b83f5b-1eef-4560-820f-91cb0ca6119a","_cell_guid":"df7295a3-cb62-4bf1-b032-0c6e112e0bc4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"id":"Krvd9GR42Sf4"}},{"cell_type":"code","source":"class Predictor:\n    def __init__(self, best_state):\n        self.cfg = cfg\n        self.tokenizer = NumberTokenizer()\n        self.model = CRNN(cfg, len(self.tokenizer.labels)).to(cfg.device)\n        self.model.load_state_dict(best_state)\n        self.model.eval()\n\n    def transcribe(self, wav_path: Path) -> str:\n        wav, sr = torchaudio.load(wav_path)\n        if sr != self.cfg.target_samplerate:\n            wav = torchaudio.transforms.Resample(sr, self.cfg.target_samplerate)(wav)\n        wav = wav.mean(dim=0, keepdim=True)\n        melspec = torchaudio.transforms.MelSpectrogram(\n            sample_rate=self.cfg.target_samplerate,\n            n_mels=self.cfg.n_mels,\n            n_fft=self.cfg.n_fft,\n            hop_length=self.cfg.hop_length,\n        )(wav)\n        melspec = torchaudio.transforms.AmplitudeToDB()(melspec)\n        melspec = melspec.squeeze(0).transpose(0, 1).unsqueeze(0).to(cfg.device)\n        with torch.no_grad():\n            X = self.model(melspec)\n        pred = self.tokenizer.decode(X[0])\n        return pred\n\n\npredictor = Predictor(best_state)","metadata":{"_uuid":"1fd6461d-b928-4730-a3b2-0895c7f82f7d","_cell_guid":"95d50479-a49b-48fa-add7-2511b7d84fde","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:40:23.722622Z","iopub.execute_input":"2025-04-20T13:40:23.722845Z","iopub.status.idle":"2025-04-20T13:40:23.758452Z","shell.execute_reply.started":"2025-04-20T13:40:23.722827Z","shell.execute_reply":"2025-04-20T13:40:23.757976Z"},"jupyter":{"outputs_hidden":false},"id":"WvR7-8lP2Sf4","collapsed":false},"outputs":[],"execution_count":14},{"cell_type":"code","source":"test_paths = [fn for fn in os.listdir(cfg.folder / 'test')]\nrecords = []\nfor fn in tqdm(test_paths):\n    pred_txt = predictor.transcribe(cfg.folder / 'test' / fn)\n    pred_num = int(pred_txt.replace(' ', '')) if pred_txt else 0\n    records.append({'filename': f\"test/{fn}\", 'transcription': pred_num})\n\nsubmission = pd.DataFrame(records)\nsubmission.to_csv('submission.csv', index=False)","metadata":{"_uuid":"c2be8203-7a77-437c-9d5f-fe718a51ef90","_cell_guid":"cb4f87a5-e7ab-4f6e-aa35-ad67fe6b378d","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:39:12.577866Z","iopub.execute_input":"2025-04-20T13:39:12.578480Z","iopub.status.idle":"2025-04-20T13:40:23.720650Z","shell.execute_reply.started":"2025-04-20T13:39:12.578454Z","shell.execute_reply":"2025-04-20T13:40:23.719886Z"},"jupyter":{"outputs_hidden":false},"id":"tQ3nSUOk2Sf4","collapsed":false},"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2582/2582 [01:11<00:00, 36.32it/s]\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true,"id":"mRy-f_0b2Sf4"},"outputs":[],"execution_count":null}]}